# ğŸ› ï¸ DataForge â€“ Automatisierte Datenpipeline mit Terraform & AWS ğŸš€

**DataForge** ist ein Infrastructure-as-Code-Projekt, das eine skalierbare, serverlose Datenpipeline auf AWS erstellt â€“ vollstÃ¤ndig automatisiert mit Terraform und Python.

## ğŸ“Œ Ziel
Daten automatisiert erfassen, speichern, transformieren â€“ und das cloudbasiert, versionierbar und erweiterbar.

---

## âš™ï¸ ArchitekturÃ¼bersicht

```text
+-------------+         +----------------+         +----------------+
| DynamoDB    |  --->   | AWS Lambda     |  --->   | S3-Bucket       |
| (Rohdaten)  |         | (Export)       |         | (Zwischenspeicher)|
+-------------+         +----------------+         +----------------+
                                                       â†“
                                                 +-------------+
                                                 | AWS Glue    |
                                                 | (optional)  |
                                                 +-------------+
                                                       â†“
                                                [SQL / Analytics]
```

---

## ğŸ”§ Technologien

- **Terraform** â€“ Infrastruktur als Code
- **AWS DynamoDB** â€“ Speicherung strukturierter & semi-strukturierter Daten
- **AWS Lambda (Python)** â€“ Exportservice in S3
- **S3** â€“ JSON-Zwischenspeicher fÃ¼r Analyse
- **AWS Glue (optional)** â€“ Datenaufbereitung
- **GitHub** â€“ CI/CD & Versionierung

---

## ğŸ—‚ï¸ Projektstruktur

```
DataForge/
â”œâ”€â”€ lambda/                 # Lambda-Code (Python)
â”‚   â””â”€â”€ dynamo_to_s3.py
â”œâ”€â”€ scripts/                # Glue-Jobs & CSV-Exporter
â”‚   â”œâ”€â”€ glue_job.py
â”‚   â””â”€â”€ insert_data.py
â”œâ”€â”€ data/                   # JSON/CSV-Testdaten
â”‚   â”œâ”€â”€ structured_data.jsonl
â”‚   â”œâ”€â”€ localfile.json
â”‚   â””â”€â”€ output.json
â”œâ”€â”€ terraform/              # Infrastruktur mit Terraform
â”‚   â”œâ”€â”€ main.tf
â”‚   â”œâ”€â”€ glue.tf
â”‚   â”œâ”€â”€ iam.tf
â”‚   â”œâ”€â”€ dynamodb.tf
â”‚   â”œâ”€â”€ ...
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸš€ Erste Schritte

```bash
terraform init
terraform apply
```

ğŸ“Œ Testdaten einfÃ¼gen:
```bash
python insert_data.py --records 10 --table all
```

---

## ğŸ“… Fortschritt & Kommende Features

- [x] Infrastruktur mit Terraform
- [x] Datenexport mit AWS Lambda
- [x] Zeitbasierter Trigger via EventBridge
- [x] Datenverarbeitung mit AWS Glue (Datenkatalog)
- [x] Glue Jobs fÃ¼r Transformation (Parquet fÃ¼r Structured, JSON, Key-Value)
- [x] Datenabfrage mit Athena (JSON & Parquet)
- [x] SQL-Persistenz mit AWS RDS (MySQL)
- [x] CSV zu Parquet (Glue Job fÃ¼r fact_appointments.csv)
- [ ] CI/CD Pipeline mit GitHub Actions
- [ ] Visuelle Architektur-Doku (draw.io)

### ğŸ”§ Geplante Erweiterungen (Phase 2)

- Direkter Glue Job Parquet â†’ MySQL (RDS)
- CSV-basierte ETL-Pipeline mit Glue â†’ RDS (bereit zur Umsetzung)
- Aufbau eines Mini-Data Warehouses (SQL)
- Visualisierung mit Power BI oder QuickSight
- GitHub Actions fÃ¼r CI/CD Checks & Deployment

---

## ğŸ“Š Datenquellen & Formate

- **Structured:** Sensor-Messdaten (ID, Timestamp, Value, Status) â†’ Parquet
- **JSON Events:** Benutzeraktionen (Login, Upload etc.) â†’ Parquet
- **Key-Value Configs:** Versionen & Parameter â†’ Parquet
- CSV-Dateien: Faktendaten zu Terminen (fact_appointments.csv) â†’ Parquet â†’ MySQL

Alle Daten werden Ã¼ber AWS Glue katalogisiert und sind per Athena abfragbar.

--- 

## ğŸ§  Autor
**Vadim Ott** â€“ Data Engineer in Progress ğŸ‘¨â€ğŸ’»  
ğŸ“ MÃ¼nchen Â· GitHub: [@voml77](https://github.com/voml77)

---

## ğŸ“¸ Screenshots / Diagramme (optional einfÃ¼gen)

> âš ï¸ Platzhalter â€“ hier kÃ¶nnen spÃ¤ter S3-Dateien, Terraform-Ausgaben, oder ein draw.io-Diagramm ergÃ¤nzt werden.
> ğŸ”§ Derzeit in Arbeit: draw.io-Diagramm zur End-to-End-Pipeline.

---

## ğŸ’¸ Hinweis zu Kosten / Ressourcen

Die AWS RDS Instanz lÃ¤uft dauerhaft, sofern sie nicht gestoppt oder gelÃ¶scht wird. Um unnÃ¶tige Kosten zu vermeiden:

- Nutze mÃ¶glichst die Free Tier-GrÃ¶ÃŸe (`db.t3.micro`) â€“ bereits gewÃ¤hlt
- RDS verursacht Kosten **auch im Leerlauf** â€“ ggf. regelmÃ¤ÃŸig stoppen
- Speicherplatz (z.â€¯B. 20 GB) wird ebenfalls berechnet

ğŸ”§ Empfehlung: Instanz manuell stoppen, wenn nicht aktiv verwendet (z.â€¯B. Ã¼ber die AWS Console)