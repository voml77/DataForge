# ğŸ› ï¸ DataForge â€“ Automatisierte Datenpipeline mit Terraform & AWS ğŸš€

**DataForge** ist ein Infrastructure-as-Code-Projekt, das eine skalierbare, serverlose Datenpipeline auf AWS erstellt â€“ vollstÃ¤ndig automatisiert mit Terraform und Python.

## ğŸ“Œ Ziel
Daten automatisiert erfassen, speichern, transformieren â€“ und das cloudbasiert, versionierbar und erweiterbar.

---

## âš™ï¸ ArchitekturÃ¼bersicht

```text
+-------------+         +----------------+         +----------------+
| DynamoDB    |  --->   | AWS Lambda     |  --->   | S3-Bucket       |
| (Rohdaten)  |         | (Export)       |         | (Zwischenspeicher)|
+-------------+         +----------------+         +----------------+
                                                       â†“
                                                 +-------------+
                                                 | AWS Glue    |
                                                 | (optional)  |
                                                 +-------------+
                                                       â†“
                                                [SQL / Analytics]
```

---

## ğŸ”§ Technologien

- **Terraform** â€“ Infrastruktur als Code
- **AWS DynamoDB** â€“ Speicherung strukturierter & semi-strukturierter Daten
- **AWS Lambda (Python)** â€“ Exportservice in S3
- **S3** â€“ JSON-Zwischenspeicher fÃ¼r Analyse
- **AWS Glue (optional)** â€“ Datenaufbereitung
- **GitHub** â€“ CI/CD & Versionierung

---

## ğŸ—‚ï¸ Projektstruktur

```
DataForge/
â”œâ”€â”€ lambda/                 # Lambda-Code (Python)
â”œâ”€â”€ insert_data.py          # Python-Skript fÃ¼r Testdaten
â”œâ”€â”€ iam.tf                  # IAM-Rollen & Policies
â”œâ”€â”€ lambda.tf               # Lambda Deployment
â”œâ”€â”€ dynamodb.tf             # DynamoDB-Tabellen
â”œâ”€â”€ outputs.tf              # (Optional) Outputs
â”œâ”€â”€ variables.tf            # (Optional) Variablen
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸš€ Erste Schritte

```bash
terraform init
terraform apply
```

ğŸ“Œ Testdaten einfÃ¼gen:
```bash
python insert_data.py --records 10 --table all
```

---

## ğŸ“… Fortschritt & Kommende Features

- [x] Infrastruktur mit Terraform
- [x] Datenexport mit AWS Lambda
- [x] Zeitbasierter Trigger via EventBridge
- [x] Datenverarbeitung mit AWS Glue (Datenkatalog)
- [ ] Glue Job fÃ¼r Transformation (z.â€¯B. Parquet, CSV)
- [ ] SQL-Persistenz (AWS RDS oder Redshift)
- [ ] Datenabfrage mit Athena oder QuickSight
- [ ] CI/CD Pipeline mit GitHub Actions
- [ ] Visuelle Architektur-Doku (draw.io)

---

## ğŸ§  Autor
**Vadim Ott** â€“ Data Engineer in Progress ğŸ‘¨â€ğŸ’»  
ğŸ“ MÃ¼nchen Â· GitHub: [@voml77](https://github.com/voml77)

---

## ğŸ“¸ Screenshots / Diagramme (optional einfÃ¼gen)

> âš ï¸ Platzhalter â€“ hier kÃ¶nnen spÃ¤ter S3-Dateien, Terraform-Ausgaben, oder ein draw.io-Diagramm ergÃ¤nzt werden.